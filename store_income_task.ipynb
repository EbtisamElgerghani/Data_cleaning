{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lqt_yzRy16Wj"
   },
   "source": [
    "## Task\n",
    "\n",
    "In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vBP3WN2O16Wp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import process\n",
    "\n",
    "\n",
    "\n",
    "from datetime import date\n",
    "# Load up store_income_data.csv\n",
    "df = pd.read_csv('store_income_data_task.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ItqLwumA16Wr"
   },
   "source": [
    "1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 77 uniqu countries in your dataset ['United States/' 'Britain' ' United States' 'Britain/' ' United Kingdom'\n",
      " 'U.K.' 'SA ' 'U.K/' 'America' 'United Kingdom' nan 'united states'\n",
      " ' S.A.' 'England ' 'UK' 'S.A./' 'ENGLAND' 'BRITAIN' 'U.K' 'U.K '\n",
      " 'America/' 'SA.' 'S.A. ' 'u.k' 'uk' ' ' 'UK.' 'England/' 'england'\n",
      " ' Britain' 'united states of america' 'UK/' 'SA/' 'SA' 'England.'\n",
      " 'UNITED KINGDOM' 'America.' 'S.A..' 's.a.' ' U.K'\n",
      " ' United States of America' 'Britain ' 'England' ' SA'\n",
      " 'United States of America.' 'United States of America/' 'United States.'\n",
      " 's. africasouth africa' ' England' 'United Kingdom '\n",
      " 'United States of America ' ' UK' 'united kingdom' 'AMERICA' 'America '\n",
      " 'UNITED STATES OF AMERICA' ' S. AfricaSouth Africa' 'america'\n",
      " 'S. AFRICASOUTH AFRICA' 'Britain.' '/' 'United Kingdom.' 'United States'\n",
      " ' America' 'UNITED STATES' 'sa' 'United States of America' 'UK '\n",
      " 'United States ' 'S. AfricaSouth Africa/' 'S.A.' 'United Kingdom/'\n",
      " 'S. AfricaSouth Africa ' 'S. AfricaSouth Africa.' 'S. AfricaSouth Africa'\n",
      " '.' 'britain']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['United States/', 'Britain', ' United States', 'Britain/',\n",
       "       ' United Kingdom', 'U.K.', 'SA ', 'U.K/', 'America',\n",
       "       'United Kingdom', nan, 'united states', ' S.A.', 'England ', 'UK',\n",
       "       'S.A./', 'ENGLAND', 'BRITAIN', 'U.K', 'U.K ', 'America/', 'SA.',\n",
       "       'S.A. ', 'u.k', 'uk', ' ', 'UK.', 'England/', 'england',\n",
       "       ' Britain', 'united states of america', 'UK/', 'SA/', 'SA',\n",
       "       'England.', 'UNITED KINGDOM', 'America.', 'S.A..', 's.a.', ' U.K',\n",
       "       ' United States of America', 'Britain ', 'England', ' SA',\n",
       "       'United States of America.', 'United States of America/',\n",
       "       'United States.', 's. africasouth africa', ' England',\n",
       "       'United Kingdom ', 'United States of America ', ' UK',\n",
       "       'united kingdom', 'AMERICA', 'America ',\n",
       "       'UNITED STATES OF AMERICA', ' S. AfricaSouth Africa', 'america',\n",
       "       'S. AFRICASOUTH AFRICA', 'Britain.', '/', 'United Kingdom.',\n",
       "       'United States', ' America', 'UNITED STATES', 'sa',\n",
       "       'United States of America', 'UK ', 'United States ',\n",
       "       'S. AfricaSouth Africa/', 'S.A.', 'United Kingdom/',\n",
       "       'S. AfricaSouth Africa ', 'S. AfricaSouth Africa.',\n",
       "       'S. AfricaSouth Africa', '.', 'britain'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# looking at all the unique values in the 'country' column.\n",
    "countries = df['country'].unique()\n",
    "print(f'there are {len(countries)} uniqu countries in your dataset', countries)\n",
    "countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "sLkzt4Hr16Wr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are 12 uniqu countries in your dataset ['united states' 'britain' 'united kingdom' 'u.k' 'sa' 'america' 's.a'\n",
      " 'england' 'uk' '' 'united states of america' 's. africasouth africa']\n"
     ]
    }
   ],
   "source": [
    "# first convert all the countrie's names into a lowercase\n",
    "df['country'] = df['country'].str.lower()\n",
    "\n",
    "# remove all trailing white spaces\n",
    "df['country'] = df['country'].str.strip()\n",
    "\n",
    "# cleaning data from '/', '.', '', ' '.\n",
    "df['country'] = df['country'].str.rstrip('/')\n",
    "df['country'] = df['country'].bfill()\n",
    "df['country'] = df['country'].str.strip('.')\n",
    "df['country'] = df['country'].bfill()\n",
    "df['country'] = df['country'].str.strip()\n",
    "df['country'] = df['country'].bfill()\n",
    "df['country'] = df['country'].str.rstrip('')\n",
    "df['country'] = df['country'].bfill()\n",
    "\n",
    "countries = df['country'].unique()\n",
    "print(f'there are {len(countries)} uniqu countries in your dataset', countries)\n",
    "\n",
    "# to fill in the empty data with the same as the one raw before.\n",
    "#df_filled = df.interpolate()\n",
    "#df_filled = df.ffill()\n",
    "#df_filled['country'] = df['country'].dropna()\n",
    "#df.isnull().sum()\n",
    "#print(df_filled[400:450])\n",
    "\n",
    "#df['country'] = df['country'].bfill()\n",
    "#df['country'] = df['country'].fillna(method = 'bfill')\n",
    "\n",
    "# display again.\n",
    "#countries = df['country'].unique()\n",
    "#print(f'there are {len(countries)} uniqu countries in your dataset', countries)\n",
    "#df['country'].isnull().sum()\n",
    "#countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to replace rows in the country column\n",
    "\n",
    "def replace_matches_in_column(df, column, string_to_match, min_ratio = 95):\n",
    "    # get a list of unique strings\n",
    "    strings = df[column].unique()\n",
    "    \n",
    "    # Get the top 10 closest matches to our input string\n",
    "    matches = fuzzywuzzy.process.extract(string_to_match, strings, \n",
    "                                         limit=10, scorer=fuzzywuzzy.fuzz.token_sort_ratio)\n",
    "\n",
    "    # Only get matches with a ratio > 90\n",
    "    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n",
    "\n",
    "    # Get the rows of all the close matches in our dataframe\n",
    "    rows_with_matches = df[column].isin(close_matches)\n",
    "\n",
    "    # Replace all rows with close matches with the input matches \n",
    "    df.loc[rows_with_matches, column] = string_to_match\n",
    "    \n",
    "    # Let us know when the function is done\n",
    "    print(\"All done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6dcDc4P16Ws"
   },
   "source": [
    "2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "qeV3CxMR16Ws"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Applied processor reduces input query to empty string, all comparisons will have score 0. [Query: '']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n",
      "All done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# replacing maches data by ratio = 95 by calling the function replace_matches_in_column.\n",
    "# replacing 5 possible same name [united kingdom,uk,u.k,england,britain] to United Kingdom\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"united kingdom\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"england\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"britain\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"u.k\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"uk\")\n",
    "df['country']= df['country'].replace('united kingdom','United Kingdom')\n",
    "df['country']= df['country'].replace('england','United Kingdom')\n",
    "df['country']= df['country'].replace('britain','United Kingdom')\n",
    "df['country']= df['country'].replace('u.k','United Kingdom')\n",
    "df['country']= df['country'].replace('uk','United Kingdom')\n",
    "\n",
    "\n",
    "# replacing maches data by ratio = 95 by calling the function replace_matches_in_column.\n",
    "# replacing 3 possible same name [united states of america,united states,'america'] to United States\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"united states\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"united states of america\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"america\")\n",
    "df.replace('united states of america', 'United States', inplace=True)\n",
    "df.replace('united states', 'United States', inplace=True)\n",
    "df.replace('america', 'United States', inplace=True)\n",
    "\n",
    "# replacing maches data by ratio = 95 by calling the function replace_matches_in_column.\n",
    "# replacing 4 possible same name[s. africasouth africa, s.a, sa, south africa'] to South Africa\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"south africa\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"s. africasouth africa\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"s.a\")\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"sa\")\n",
    "df.replace('south africa', 'South Africa', inplace=True)\n",
    "df.replace('s. africasouth africa', 'South Africa', inplace=True)\n",
    "df.replace('s.a', 'South Africa', inplace=True)\n",
    "df.replace('sa', 'South Africa', inplace=True)\n",
    "\n",
    "replace_matches_in_column(df=df, column='country', string_to_match=\"\")\n",
    "df.replace('', np.nan, inplace=True)\n",
    "#df.dropna(inplace=True)\n",
    "df['country'] = df['country'].ffill()\n",
    "#df['country'] = df['country'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#countries2 = df['country'].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 unique countries\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['United Kingdom', 'South Africa', 'United States'], dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#df.head(30)\n",
    "countries = df['country'].unique()\n",
    "print(f\"There are {len(countries)} unique countries\")\n",
    "\n",
    "df['country'].isnull().sum()\n",
    "countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UJZDMTwP16Ws"
   },
   "source": [
    "3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "DataFrame.assign() takes 1 positional argument but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#new_column1 = df.insert(7,'days_ago','date_measured')\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdays_gone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdate_measured\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mTypeError\u001b[0m: DataFrame.assign() takes 1 positional argument but 3 were given"
     ]
    }
   ],
   "source": [
    "#new_column1 = df.insert(7,'days_ago','date_measured')\n",
    "df= df.assign('days_gone', df.date_measured)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
